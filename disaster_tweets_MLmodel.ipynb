{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disaster-tweets-MLmodel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSGWKgWim6DtzZ1U8oTqQX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangJiao85/disaster-tweets-kaggle/blob/master/disaster_tweets_MLmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGc_RCYnhfqr",
        "colab_type": "text"
      },
      "source": [
        "# Disaster Tweets \n",
        "\n",
        "This notebook will build a machine learning model that predicts which Tweets are about real disasters and which one's aren't. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yogHrZiEkt",
        "colab_type": "text"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgCJ05BT6snQ",
        "colab_type": "text"
      },
      "source": [
        "Set up Kaggle environment and essential modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHS_EfzWheY4",
        "colab_type": "code",
        "outputId": "e848ff70-46df-40c6-9b53-8f5b8aff7008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# Load essential modules\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "import sklearn.model_selection as ms\n",
        "import sklearn.metrics as skm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKr1_1vbigAE",
        "colab_type": "code",
        "outputId": "bfc4064b-dc32-452b-a388-8e19d5b75923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Google colab Kaggle setting\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] =  <kaggle_username>\n",
        "os.environ['KAGGLE_KEY'] =  <kaggle_key>\n",
        "\n",
        "!kaggle competitions download -c 'nlp-getting-started'\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv to /content\n",
            "\r  0% 0.00/965k [00:00<?, ?B/s]\n",
            "100% 965k/965k [00:00<00:00, 64.4MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/22.2k [00:00<?, ?B/s]\n",
            "100% 22.2k/22.2k [00:00<00:00, 19.6MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/411k [00:00<?, ?B/s]\n",
            "100% 411k/411k [00:00<00:00, 133MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jvKHGfzju4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "df_sub = pd.read_csv('sample_submission.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-xfHniAnt6_",
        "colab_type": "text"
      },
      "source": [
        "## Extract feature vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aneC09CD654g",
        "colab_type": "text"
      },
      "source": [
        "- id\n",
        "- keyword\n",
        "- location\n",
        "- text\n",
        "- target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M06lY_Vx1nbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e0b1135-aa0d-48b6-dc7e-505d3de50875"
      },
      "source": [
        "df_train.duplicated().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh5wH5RzoLti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# reshape 2D to 1D\n",
        "class trans_ravel(TransformerMixin, BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.ravel()\n",
        "\n",
        "# keyword\n",
        "kw_vec = Pipeline([\n",
        "    ('kw_imp', SimpleImputer(strategy='constant')),\n",
        "    ('kw_ravel', trans_ravel()),\n",
        "    ('kw_vect', CountVectorizer())                   \n",
        "    ], verbose = True)\n",
        "\n",
        "# location\n",
        "loc_vec = Pipeline([\n",
        "    ('loc_imp', SimpleImputer(strategy = 'constant')),\n",
        "    ('loc_ohe', OneHotEncoder(handle_unknown='ignore'))                    \n",
        "    ], verbose = True)\n",
        "\n",
        "# text\n",
        "text_vec = Pipeline([\n",
        "    ('text_tfidf', TfidfVectorizer())                     \n",
        "    ], verbose = True)\n",
        "\n",
        "# \n",
        "transformer = ColumnTransformer([\n",
        "    ('kw_vec', kw_vec, ['keyword']),\n",
        "    ('loc_vec', loc_vec, ['location']),\n",
        "    ('text_vec', text_vec, 'text')                             \n",
        "    ], remainder = 'drop')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvvkQ_n3rzTT",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQxVc525kTZs",
        "colab_type": "text"
      },
      "source": [
        "### Some functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjjeDx_HUEP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_grid_search(pip_clf, tuned_parameters):\n",
        "    from pprint import pprint\n",
        "    from time import time\n",
        "    if __name__ == \"__main__\":\n",
        "        # multiprocessing requires the fork to happen in a __main__ protected block\n",
        "\n",
        "        # find the best parameters\n",
        "        grid_search = ms.GridSearchCV(pip_clf, tuned_parameters, n_jobs=-1, \n",
        "                                  verbose=1)\n",
        "\n",
        "        print(\"Performing grid search...\")\n",
        "        print(\"pipeline:\", [name for name, _ in pip_clf.steps])\n",
        "        print(\"parameters to be tuned:\")\n",
        "        pprint(tuned_parameters)\n",
        "        t0 = time()\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        print(\"Best parameters set found on train set:\\n\")\n",
        "        print(grid_search.best_params_)\n",
        "        print(\"Grid scores on train set:\\n\")\n",
        "        means = grid_search.cv_results_['mean_test_score']\n",
        "        stds = grid_search.cv_results_['std_test_score']\n",
        "        for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
        "            print(\"{:.3f} (+/-{:.3f}) for {}\".format(mean, std, params))\n",
        "\n",
        "        print(\"\\nDetailed classification report:\\n\")\n",
        "        y_pred = grid_search.predict(X_test)\n",
        "        print(skm.classification_report(y_test, y_pred))\n",
        "    return\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shAZsGJDk_F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_sub_csv(pip_clf, sub_file = 'submission.csv', ldl = False):\n",
        "    y_pred = pip_clf.predict(df_test)\n",
        "    df_sub = pd.DataFrame(data={\n",
        "        'id': df_test['id'],\n",
        "        'target': y_pred\n",
        "    })\n",
        "    df.head()\n",
        "    df_sub.to_csv(sub_file, index=False)\n",
        "\n",
        "    if(ldl):\n",
        "        from google.colab import files\n",
        "        files.download(sub_file)\n",
        "    \n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VGgKC5bnN1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = ms.train_test_split(\n",
        "    df_train[['keyword', 'location', 'text']],\n",
        "    df_train['target'],\n",
        "    test_size = 0.3,\n",
        "    random_state = 1234\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG6XIF376Nfu",
        "colab_type": "text"
      },
      "source": [
        "### Support Vector Classifier (SVC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h6QLy_Kr1KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "pip_svc = Pipeline([\n",
        "    ('trans', transformer),\n",
        "    ('clf', LinearSVC())                    \n",
        "    ], verbose = True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyos7lRYtWX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "a0ec3195-9416-4f0e-b913-46249b40c26e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_train[['keyword', 'location', 'text']], df_train['target'],\n",
        "    test_size = 0.3, random_state = 1234\n",
        ")\n",
        "\n",
        "pip_fit = pip_svc.fit(X_train, y_train)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing kw_imp, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing kw_ravel, total=   0.0s\n",
            "[Pipeline] ........... (step 3 of 3) Processing kw_vect, total=   0.0s\n",
            "[Pipeline] ........... (step 1 of 2) Processing loc_imp, total=   0.0s\n",
            "[Pipeline] ........... (step 2 of 2) Processing loc_ohe, total=   0.0s\n",
            "[Pipeline] ........ (step 1 of 1) Processing text_tfidf, total=   0.1s\n",
            "[Pipeline] ............. (step 1 of 2) Processing trans, total=   0.2s\n",
            "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQn9mrvluYQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "d3f38c9d-5dc4-4d93-805a-c6c797665e0c"
      },
      "source": [
        "y_pred = pip_svc.predict(X_test)\n",
        "print(skm.classification_report(y_test, y_pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82      1288\n",
            "           1       0.78      0.73      0.76       996\n",
            "\n",
            "    accuracy                           0.79      2284\n",
            "   macro avg       0.79      0.79      0.79      2284\n",
            "weighted avg       0.79      0.79      0.79      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z-j3EBun7lP",
        "colab_type": "text"
      },
      "source": [
        "#### Grid search with cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J0E9pjYoNVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tuned_parameters = ({\n",
        "    '': (),\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvJPRsYy7WTN",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Boosting Decision Trees (GBDT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_8TcPT77Uqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "clf_gbc = GradientBoostingClassifier(\n",
        "    n_estimators=100, \n",
        "    learning_rate=.1, \n",
        "    max_leaf_nodes=10,\n",
        "    subsample=0.5, \n",
        "    random_state=0\n",
        "    )\n",
        "\n",
        "pip_gbc = Pipeline([\n",
        "    ('trans', transformer),\n",
        "    ('clf_gbc', clf_gbc)                    \n",
        "    ], verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPHkv75X8rox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "3932356f-366e-488a-8915-ab2259bdbe19"
      },
      "source": [
        "X_train, X_test, y_train, y_test = ms.train_test_split(\n",
        "    df_train[['keyword', 'location', 'text']], df_train['target'],\n",
        "    test_size = 0.3, random_state = 1234\n",
        "    )\n",
        "\n",
        "pip_gbc_fit = pip_gbc.fit(X_train, y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing kw_imp, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing kw_ravel, total=   0.0s\n",
            "[Pipeline] ........... (step 3 of 3) Processing kw_vect, total=   0.0s\n",
            "[Pipeline] ........... (step 1 of 2) Processing loc_imp, total=   0.0s\n",
            "[Pipeline] ........... (step 2 of 2) Processing loc_ohe, total=   0.0s\n",
            "[Pipeline] ........ (step 1 of 1) Processing text_tfidf, total=   0.1s\n",
            "[Pipeline] ............. (step 1 of 2) Processing trans, total=   0.2s\n",
            "[Pipeline] ........... (step 2 of 2) Processing clf_gbc, total=   2.8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NUBbqBM9372",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "9743a8d0-fd22-4ebb-8058-ce87d12e2e0e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = pip_gbc.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(pip_gbc.score(X_test, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.85      0.80      1288\n",
            "           1       0.76      0.63      0.69       996\n",
            "\n",
            "    accuracy                           0.75      2284\n",
            "   macro avg       0.76      0.74      0.74      2284\n",
            "weighted avg       0.76      0.75      0.75      2284\n",
            "\n",
            "0.7543782837127846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxo5X3q1UFAR",
        "colab_type": "text"
      },
      "source": [
        "#### Grid search with cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpwr87_Paguu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53b4e3fb-befb-4cb3-cf8b-21cc962eea76"
      },
      "source": [
        "tuned_parameters = {\n",
        "    'clf_gbc__n_estimators': (10, 100, 200),\n",
        "    'clf_gbc__learning_rate': (1., 0.5, 0.1),\n",
        "    'clf_gbc__max_leaf_nodes': (2, 5, 10, 20),\n",
        "}\n",
        "\n",
        "perform_grid_search(pip_gbc, tuned_parameters)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['trans', 'clf_gbc']\n",
            "parameters to be tuned:\n",
            "{'clf_gbc__learning_rate': (1.0, 0.5, 0.1),\n",
            " 'clf_gbc__max_leaf_nodes': (2, 5, 10, 20),\n",
            " 'clf_gbc__n_estimators': (10, 100, 200)}\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  5.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing kw_imp, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing kw_ravel, total=   0.0s\n",
            "[Pipeline] ........... (step 3 of 3) Processing kw_vect, total=   0.0s\n",
            "[Pipeline] ........... (step 1 of 2) Processing loc_imp, total=   0.0s\n",
            "[Pipeline] ........... (step 2 of 2) Processing loc_ohe, total=   0.0s\n",
            "[Pipeline] ........ (step 1 of 1) Processing text_tfidf, total=   0.1s\n",
            "[Pipeline] ............. (step 1 of 2) Processing trans, total=   0.2s\n",
            "[Pipeline] ........... (step 2 of 2) Processing clf_gbc, total=   5.3s\n",
            "Best parameters set found on train set:\n",
            "\n",
            "{'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 200}\n",
            "Grid scores on train set:\n",
            "\n",
            "0.663 (+/-0.016) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 2, 'clf_gbc__n_estimators': 10}\n",
            "0.727 (+/-0.020) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 2, 'clf_gbc__n_estimators': 100}\n",
            "0.724 (+/-0.014) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 2, 'clf_gbc__n_estimators': 200}\n",
            "0.709 (+/-0.016) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 10}\n",
            "0.714 (+/-0.019) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 100}\n",
            "0.713 (+/-0.013) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 200}\n",
            "0.702 (+/-0.017) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 10}\n",
            "0.715 (+/-0.016) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 100}\n",
            "0.709 (+/-0.021) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 200}\n",
            "0.702 (+/-0.017) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 10}\n",
            "0.715 (+/-0.016) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 100}\n",
            "0.709 (+/-0.021) for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 200}\n",
            "0.657 (+/-0.017) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 2, 'clf_gbc__n_estimators': 10}\n",
            "0.746 (+/-0.016) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 2, 'clf_gbc__n_estimators': 100}\n",
            "0.746 (+/-0.016) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 2, 'clf_gbc__n_estimators': 200}\n",
            "0.704 (+/-0.011) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 10}\n",
            "0.734 (+/-0.010) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 100}\n",
            "0.733 (+/-0.004) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 200}\n",
            "0.696 (+/-0.021) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 10}\n",
            "0.725 (+/-0.012) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 100}\n",
            "0.725 (+/-0.007) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 200}\n",
            "0.696 (+/-0.021) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 10}\n",
            "0.725 (+/-0.012) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 100}\n",
            "0.725 (+/-0.007) for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 200}\n",
            "0.630 (+/-0.016) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 2, 'clf_gbc__n_estimators': 10}\n",
            "0.711 (+/-0.020) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 2, 'clf_gbc__n_estimators': 100}\n",
            "0.734 (+/-0.016) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 2, 'clf_gbc__n_estimators': 200}\n",
            "0.672 (+/-0.015) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 10}\n",
            "0.747 (+/-0.026) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 100}\n",
            "0.765 (+/-0.018) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 200}\n",
            "0.675 (+/-0.015) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 10}\n",
            "0.744 (+/-0.023) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 100}\n",
            "0.761 (+/-0.015) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 200}\n",
            "0.675 (+/-0.015) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 10}\n",
            "0.744 (+/-0.023) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 100}\n",
            "0.761 (+/-0.015) for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 200}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.86      0.81      1288\n",
            "           1       0.79      0.67      0.72       996\n",
            "\n",
            "    accuracy                           0.78      2284\n",
            "   macro avg       0.78      0.77      0.77      2284\n",
            "weighted avg       0.78      0.78      0.78      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAXe0xG_KHoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "583245f4-a5bf-43c6-9a18-e1036b72eca2"
      },
      "source": [
        "pip_gbc.get_params().keys()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'trans', 'clf_gbc', 'trans__n_jobs', 'trans__remainder', 'trans__sparse_threshold', 'trans__transformer_weights', 'trans__transformers', 'trans__verbose', 'trans__kw_vec', 'trans__loc_vec', 'trans__text_vec', 'trans__kw_vec__memory', 'trans__kw_vec__steps', 'trans__kw_vec__verbose', 'trans__kw_vec__kw_imp', 'trans__kw_vec__kw_ravel', 'trans__kw_vec__kw_vect', 'trans__kw_vec__kw_imp__add_indicator', 'trans__kw_vec__kw_imp__copy', 'trans__kw_vec__kw_imp__fill_value', 'trans__kw_vec__kw_imp__missing_values', 'trans__kw_vec__kw_imp__strategy', 'trans__kw_vec__kw_imp__verbose', 'trans__kw_vec__kw_vect__analyzer', 'trans__kw_vec__kw_vect__binary', 'trans__kw_vec__kw_vect__decode_error', 'trans__kw_vec__kw_vect__dtype', 'trans__kw_vec__kw_vect__encoding', 'trans__kw_vec__kw_vect__input', 'trans__kw_vec__kw_vect__lowercase', 'trans__kw_vec__kw_vect__max_df', 'trans__kw_vec__kw_vect__max_features', 'trans__kw_vec__kw_vect__min_df', 'trans__kw_vec__kw_vect__ngram_range', 'trans__kw_vec__kw_vect__preprocessor', 'trans__kw_vec__kw_vect__stop_words', 'trans__kw_vec__kw_vect__strip_accents', 'trans__kw_vec__kw_vect__token_pattern', 'trans__kw_vec__kw_vect__tokenizer', 'trans__kw_vec__kw_vect__vocabulary', 'trans__loc_vec__memory', 'trans__loc_vec__steps', 'trans__loc_vec__verbose', 'trans__loc_vec__loc_imp', 'trans__loc_vec__loc_ohe', 'trans__loc_vec__loc_imp__add_indicator', 'trans__loc_vec__loc_imp__copy', 'trans__loc_vec__loc_imp__fill_value', 'trans__loc_vec__loc_imp__missing_values', 'trans__loc_vec__loc_imp__strategy', 'trans__loc_vec__loc_imp__verbose', 'trans__loc_vec__loc_ohe__categories', 'trans__loc_vec__loc_ohe__drop', 'trans__loc_vec__loc_ohe__dtype', 'trans__loc_vec__loc_ohe__handle_unknown', 'trans__loc_vec__loc_ohe__sparse', 'trans__text_vec__memory', 'trans__text_vec__steps', 'trans__text_vec__verbose', 'trans__text_vec__text_tfidf', 'trans__text_vec__text_tfidf__analyzer', 'trans__text_vec__text_tfidf__binary', 'trans__text_vec__text_tfidf__decode_error', 'trans__text_vec__text_tfidf__dtype', 'trans__text_vec__text_tfidf__encoding', 'trans__text_vec__text_tfidf__input', 'trans__text_vec__text_tfidf__lowercase', 'trans__text_vec__text_tfidf__max_df', 'trans__text_vec__text_tfidf__max_features', 'trans__text_vec__text_tfidf__min_df', 'trans__text_vec__text_tfidf__ngram_range', 'trans__text_vec__text_tfidf__norm', 'trans__text_vec__text_tfidf__preprocessor', 'trans__text_vec__text_tfidf__smooth_idf', 'trans__text_vec__text_tfidf__stop_words', 'trans__text_vec__text_tfidf__strip_accents', 'trans__text_vec__text_tfidf__sublinear_tf', 'trans__text_vec__text_tfidf__token_pattern', 'trans__text_vec__text_tfidf__tokenizer', 'trans__text_vec__text_tfidf__use_idf', 'trans__text_vec__text_tfidf__vocabulary', 'clf_gbc__ccp_alpha', 'clf_gbc__criterion', 'clf_gbc__init', 'clf_gbc__learning_rate', 'clf_gbc__loss', 'clf_gbc__max_depth', 'clf_gbc__max_features', 'clf_gbc__max_leaf_nodes', 'clf_gbc__min_impurity_decrease', 'clf_gbc__min_impurity_split', 'clf_gbc__min_samples_leaf', 'clf_gbc__min_samples_split', 'clf_gbc__min_weight_fraction_leaf', 'clf_gbc__n_estimators', 'clf_gbc__n_iter_no_change', 'clf_gbc__presort', 'clf_gbc__random_state', 'clf_gbc__subsample', 'clf_gbc__tol', 'clf_gbc__validation_fraction', 'clf_gbc__verbose', 'clf_gbc__warm_start'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6HjA6UDKO0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "f1af3531-515e-4626-c7f7-98ce7ba1407e"
      },
      "source": [
        "pip_gbc.set_params(clf_gbc__learning_rate = 0.1) \n",
        "pip_gbc.set_params(clf_gbc__max_leaf_nodes = 5)\n",
        "pip_gbc.set_params(clf_gbc__n_estimators = 200)\n",
        "\n",
        "tuned_parameters = ({\n",
        "    'trans__text_vec__text_tfidf__max_df': (0.5, 0.8, 1.0),\n",
        "    'trans__text_vec__text_tfidf__min_df': (0.0, 0.1),\n",
        "    'trans__text_vec__text_tfidf__ngram_range': ((1,1), (1,2), (2,2)),\n",
        "})\n",
        "\n",
        "perform_grid_search(pip_gbc, tuned_parameters)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['trans', 'clf_gbc']\n",
            "parameters to be tuned:\n",
            "{'trans__text_vec__text_tfidf__max_df': (0.5, 0.8, 1.0),\n",
            " 'trans__text_vec__text_tfidf__min_df': (0.0, 0.1),\n",
            " 'trans__text_vec__text_tfidf__ngram_range': ((1, 1), (1, 2), (2, 2))}\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  5.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing kw_imp, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing kw_ravel, total=   0.0s\n",
            "[Pipeline] ........... (step 3 of 3) Processing kw_vect, total=   0.0s\n",
            "[Pipeline] ........... (step 1 of 2) Processing loc_imp, total=   0.0s\n",
            "[Pipeline] ........... (step 2 of 2) Processing loc_ohe, total=   0.0s\n",
            "[Pipeline] ........ (step 1 of 1) Processing text_tfidf, total=   0.1s\n",
            "[Pipeline] ............. (step 1 of 2) Processing trans, total=   0.1s\n",
            "[Pipeline] ........... (step 2 of 2) Processing clf_gbc, total=   5.1s\n",
            "Best parameters set found on train set:\n",
            "\n",
            "{'trans__text_vec__text_tfidf__max_df': 0.5, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (1, 1)}\n",
            "Grid scores on train set:\n",
            "\n",
            "0.766 (+/-0.020) for {'trans__text_vec__text_tfidf__max_df': 0.5, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (1, 1)}\n",
            "0.763 (+/-0.016) for {'trans__text_vec__text_tfidf__max_df': 0.5, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (1, 2)}\n",
            "0.725 (+/-0.012) for {'trans__text_vec__text_tfidf__max_df': 0.5, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (2, 2)}\n",
            "0.724 (+/-0.016) for {'trans__text_vec__text_tfidf__max_df': 0.5, 'trans__text_vec__text_tfidf__min_df': 0.1, 'trans__text_vec__text_tfidf__ngram_range': (1, 1)}\n",
            "0.728 (+/-0.011) for {'trans__text_vec__text_tfidf__max_df': 0.5, 'trans__text_vec__text_tfidf__min_df': 0.1, 'trans__text_vec__text_tfidf__ngram_range': (1, 2)}\n",
            "0.726 (+/-0.011) for {'trans__text_vec__text_tfidf__max_df': 0.5, 'trans__text_vec__text_tfidf__min_df': 0.1, 'trans__text_vec__text_tfidf__ngram_range': (2, 2)}\n",
            "0.765 (+/-0.018) for {'trans__text_vec__text_tfidf__max_df': 0.8, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (1, 1)}\n",
            "0.761 (+/-0.013) for {'trans__text_vec__text_tfidf__max_df': 0.8, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (1, 2)}\n",
            "0.725 (+/-0.012) for {'trans__text_vec__text_tfidf__max_df': 0.8, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (2, 2)}\n",
            "0.728 (+/-0.013) for {'trans__text_vec__text_tfidf__max_df': 0.8, 'trans__text_vec__text_tfidf__min_df': 0.1, 'trans__text_vec__text_tfidf__ngram_range': (1, 1)}\n",
            "0.730 (+/-0.017) for {'trans__text_vec__text_tfidf__max_df': 0.8, 'trans__text_vec__text_tfidf__min_df': 0.1, 'trans__text_vec__text_tfidf__ngram_range': (1, 2)}\n",
            "0.726 (+/-0.011) for {'trans__text_vec__text_tfidf__max_df': 0.8, 'trans__text_vec__text_tfidf__min_df': 0.1, 'trans__text_vec__text_tfidf__ngram_range': (2, 2)}\n",
            "0.765 (+/-0.018) for {'trans__text_vec__text_tfidf__max_df': 1.0, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (1, 1)}\n",
            "0.761 (+/-0.013) for {'trans__text_vec__text_tfidf__max_df': 1.0, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (1, 2)}\n",
            "0.725 (+/-0.012) for {'trans__text_vec__text_tfidf__max_df': 1.0, 'trans__text_vec__text_tfidf__min_df': 0.0, 'trans__text_vec__text_tfidf__ngram_range': (2, 2)}\n",
            "0.728 (+/-0.013) for {'trans__text_vec__text_tfidf__max_df': 1.0, 'trans__text_vec__text_tfidf__min_df': 0.1, 'trans__text_vec__text_tfidf__ngram_range': (1, 1)}\n",
            "0.730 (+/-0.017) for {'trans__text_vec__text_tfidf__max_df': 1.0, 'trans__text_vec__text_tfidf__min_df': 0.1, 'trans__text_vec__text_tfidf__ngram_range': (1, 2)}\n",
            "0.726 (+/-0.011) for {'trans__text_vec__text_tfidf__max_df': 1.0, 'trans__text_vec__text_tfidf__min_df': 0.1, 'trans__text_vec__text_tfidf__ngram_range': (2, 2)}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.86      0.81      1288\n",
            "           1       0.79      0.67      0.73       996\n",
            "\n",
            "    accuracy                           0.78      2284\n",
            "   macro avg       0.78      0.77      0.77      2284\n",
            "weighted avg       0.78      0.78      0.78      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSZcuflCKQF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}