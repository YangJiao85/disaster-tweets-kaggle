{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disaster-tweets-MLmodel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5JkwGT+Tpq/whxVNyDnTv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangJiao85/disaster-tweets-kaggle/blob/master/disaster_tweets_MLmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGc_RCYnhfqr",
        "colab_type": "text"
      },
      "source": [
        "# Disaster Tweets \n",
        "\n",
        "This notebook will build a machine learning model that predicts which Tweets are about real disasters and which one's aren't. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yogHrZiEkt",
        "colab_type": "text"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgCJ05BT6snQ",
        "colab_type": "text"
      },
      "source": [
        "Set up Kaggle environment and essential modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHS_EfzWheY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load essential modules\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "import sklearn.model_selection as ms\n",
        "import sklearn.metrics as skm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKr1_1vbigAE",
        "colab_type": "code",
        "outputId": "613b27c8-fdaf-4109-de08-8a5f498e7262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Google colab Kaggle setting\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] =  <kaggle_username>\n",
        "os.environ['KAGGLE_KEY'] = <kaggle_key>\n",
        "\n",
        "!kaggle competitions download -c 'nlp-getting-started'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/22.2k [00:00<?, ?B/s]\n",
            "100% 22.2k/22.2k [00:00<00:00, 37.1MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/965k [00:00<?, ?B/s]\n",
            "100% 965k/965k [00:00<00:00, 63.7MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/411k [00:00<?, ?B/s]\n",
            "100% 411k/411k [00:00<00:00, 56.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jvKHGfzju4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "df_sub = pd.read_csv('sample_submission.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-xfHniAnt6_",
        "colab_type": "text"
      },
      "source": [
        "## Extract feature vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aneC09CD654g",
        "colab_type": "text"
      },
      "source": [
        "- id\n",
        "- keyword\n",
        "- location\n",
        "- text\n",
        "- target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M06lY_Vx1nbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "279abf9b-aacf-4bdc-ec4a-eaadcd12d922"
      },
      "source": [
        "df_train.duplicated().sum()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh5wH5RzoLti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# reshape 2D to 1D\n",
        "class trans_ravel(TransformerMixin, BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.ravel()\n",
        "\n",
        "# keyword\n",
        "kw_vec = Pipeline([\n",
        "    ('kw_imp', SimpleImputer(strategy='constant')),\n",
        "    ('kw_ravel', trans_ravel()),\n",
        "    ('kw_vect', CountVectorizer())                   \n",
        "    ], verbose = True)\n",
        "\n",
        "# location\n",
        "loc_vec = Pipeline([\n",
        "    ('loc_imp', SimpleImputer(strategy = 'constant')),\n",
        "    ('loc_ohe', OneHotEncoder(handle_unknown='ignore'))                    \n",
        "    ], verbose = True)\n",
        "\n",
        "# text\n",
        "text_vec = Pipeline([\n",
        "    ('text_tfidf', TfidfVectorizer())                     \n",
        "    ], verbose = True)\n",
        "\n",
        "# \n",
        "transformer = ColumnTransformer([\n",
        "    ('kw_vec', kw_vec, ['keyword']),\n",
        "    ('loc_vec', loc_vec, ['location']),\n",
        "    ('text_vec', text_vec, 'text')                             \n",
        "    ], remainder = 'drop')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvvkQ_n3rzTT",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG6XIF376Nfu",
        "colab_type": "text"
      },
      "source": [
        "### Support Vector Classifier (SVC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h6QLy_Kr1KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "pip_clf = Pipeline([\n",
        "    ('trans', transformer),\n",
        "    ('clf', LinearSVC())                    \n",
        "    ], verbose = True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyos7lRYtWX0",
        "colab_type": "code",
        "outputId": "792d3b1f-0d7b-40cf-8b03-860474eea08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_train[['keyword', 'location', 'text']], df_train['target'],\n",
        "    test_size = 0.3, random_state = 1234\n",
        ")\n",
        "\n",
        "pip_fit = pip_clf.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing kw_imp, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing kw_ravel, total=   0.0s\n",
            "[Pipeline] ........... (step 3 of 3) Processing kw_vect, total=   0.0s\n",
            "[Pipeline] ........... (step 1 of 2) Processing loc_imp, total=   0.0s\n",
            "[Pipeline] ........... (step 2 of 2) Processing loc_ohe, total=   0.0s\n",
            "[Pipeline] ........ (step 1 of 1) Processing text_tfidf, total=   0.1s\n",
            "[Pipeline] ............. (step 1 of 2) Processing trans, total=   0.1s\n",
            "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQn9mrvluYQU",
        "colab_type": "code",
        "outputId": "5a8b6d11-3238-47ab-ecbe-bb23832a5d68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = pip_clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82      1288\n",
            "           1       0.78      0.73      0.76       996\n",
            "\n",
            "    accuracy                           0.79      2284\n",
            "   macro avg       0.79      0.79      0.79      2284\n",
            "weighted avg       0.79      0.79      0.79      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvJPRsYy7WTN",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Boosting Decision Trees (GBDT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_8TcPT77Uqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "clf_gbc = GradientBoostingClassifier(\n",
        "    n_estimators=100, \n",
        "    learning_rate=.1, \n",
        "    max_leaf_nodes=10,\n",
        "    subsample=0.5, \n",
        "    random_state=0\n",
        "    )\n",
        "\n",
        "pip_gbc = Pipeline([\n",
        "    ('trans', transformer),\n",
        "    ('clf_gbc', clf_gbc)                    \n",
        "    ], verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPHkv75X8rox",
        "colab_type": "code",
        "outputId": "3eb1c235-bb0d-4610-dbc2-2fbe5628c4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = ms.train_test_split(\n",
        "    df_train[['keyword', 'location', 'text']], df_train['target'],\n",
        "    test_size = 0.3, random_state = 1234\n",
        "    )\n",
        "\n",
        "pip_gbc_fit = pip_gbc.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing kw_imp, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing kw_ravel, total=   0.0s\n",
            "[Pipeline] ........... (step 3 of 3) Processing kw_vect, total=   0.0s\n",
            "[Pipeline] ........... (step 1 of 2) Processing loc_imp, total=   0.0s\n",
            "[Pipeline] ........... (step 2 of 2) Processing loc_ohe, total=   0.0s\n",
            "[Pipeline] ........ (step 1 of 1) Processing text_tfidf, total=   0.1s\n",
            "[Pipeline] ............. (step 1 of 2) Processing trans, total=   0.1s\n",
            "[Pipeline] ........... (step 2 of 2) Processing clf_gbc, total=   2.7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NUBbqBM9372",
        "colab_type": "code",
        "outputId": "4bba8ec8-6c8e-4818-ec19-3df851cf5358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = pip_gbc.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(pip_gbc.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.85      0.80      1288\n",
            "           1       0.76      0.63      0.69       996\n",
            "\n",
            "    accuracy                           0.75      2284\n",
            "   macro avg       0.76      0.74      0.74      2284\n",
            "weighted avg       0.76      0.75      0.75      2284\n",
            "\n",
            "0.7543782837127846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxo5X3q1UFAR",
        "colab_type": "text"
      },
      "source": [
        "#### Grid search with cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjjeDx_HUEP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6f3494f-d3a3-4334-9ade-32490033a3bd"
      },
      "source": [
        "from pprint import pprint\n",
        "from time import time\n",
        "\n",
        "tuned_parameters = {\n",
        "    'clf_gbc__n_estimators': (10, 100, 200),\n",
        "    'clf_gbc__learning_rate': (1., 0.5, 0.1),\n",
        "    'clf_gbc__max_leaf_nodes': (2, 5, 10, 20),\n",
        "}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # multiprocessing requires the fork to happen in a __main__ protected block\n",
        "\n",
        "    # find the best parameters\n",
        "    grid_search = ms.GridSearchCV(pip_gbc, tuned_parameters, n_jobs=-1, \n",
        "                                  verbose=1)\n",
        "\n",
        "    print(\"Performing grid search...\")\n",
        "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
        "    print(\"parameters to be tuned:\")\n",
        "    pprint(tuned_paramerters)\n",
        "    t0 = time()\n",
        "    grid_search.fit()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['trans', 'clf_gbc']\n",
            "parameters to be tuned:\n",
            "{'clf_gbc__learning_rate': (1.0, 0.5, 0.1),\n",
            " 'clf_gbc__max_leaf_nodes': (1, 5, 10, 20),\n",
            " 'clf_gbc__n_estimators': (10, 100, 200)}\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   55.0s\n",
            "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  4.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing kw_imp, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing kw_ravel, total=   0.0s\n",
            "[Pipeline] ........... (step 3 of 3) Processing kw_vect, total=   0.0s\n",
            "[Pipeline] ........... (step 1 of 2) Processing loc_imp, total=   0.0s\n",
            "[Pipeline] ........... (step 2 of 2) Processing loc_ohe, total=   0.0s\n",
            "[Pipeline] ........ (step 1 of 1) Processing text_tfidf, total=   0.1s\n",
            "[Pipeline] ............. (step 1 of 2) Processing trans, total=   0.2s\n",
            "[Pipeline] ........... (step 2 of 2) Processing clf_gbc, total=   5.1s\n",
            "done in 258.752s\n",
            "\n",
            "Best score: 0.765\n",
            "Best parameter set:\n",
            "\tclf_gbc__learning_rate: 0.1\n",
            "\tclf_gbc__max_leaf_nodes: 5\n",
            "\tclf_gbc__n_estimators: 200\n",
            "nan (+/-nan for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 1, 'clf_gbc__n_estimators': 10}\n",
            "nan (+/-nan for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 1, 'clf_gbc__n_estimators': 100}\n",
            "nan (+/-nan for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 1, 'clf_gbc__n_estimators': 200}\n",
            "0.709 (+/-0.033 for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 10}\n",
            "0.714 (+/-0.039 for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 100}\n",
            "0.713 (+/-0.026 for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 200}\n",
            "0.702 (+/-0.034 for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 10}\n",
            "0.715 (+/-0.032 for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 100}\n",
            "0.709 (+/-0.042 for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 200}\n",
            "0.702 (+/-0.034 for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 10}\n",
            "0.715 (+/-0.032 for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 100}\n",
            "0.709 (+/-0.042 for {'clf_gbc__learning_rate': 1.0, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 200}\n",
            "nan (+/-nan for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 1, 'clf_gbc__n_estimators': 10}\n",
            "nan (+/-nan for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 1, 'clf_gbc__n_estimators': 100}\n",
            "nan (+/-nan for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 1, 'clf_gbc__n_estimators': 200}\n",
            "0.704 (+/-0.022 for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 10}\n",
            "0.734 (+/-0.019 for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 100}\n",
            "0.733 (+/-0.007 for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 200}\n",
            "0.696 (+/-0.042 for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 10}\n",
            "0.725 (+/-0.024 for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 100}\n",
            "0.725 (+/-0.013 for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 200}\n",
            "0.696 (+/-0.042 for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 10}\n",
            "0.725 (+/-0.024 for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 100}\n",
            "0.725 (+/-0.013 for {'clf_gbc__learning_rate': 0.5, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 200}\n",
            "nan (+/-nan for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 1, 'clf_gbc__n_estimators': 10}\n",
            "nan (+/-nan for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 1, 'clf_gbc__n_estimators': 100}\n",
            "nan (+/-nan for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 1, 'clf_gbc__n_estimators': 200}\n",
            "0.672 (+/-0.029 for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 10}\n",
            "0.747 (+/-0.052 for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 100}\n",
            "0.765 (+/-0.036 for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 5, 'clf_gbc__n_estimators': 200}\n",
            "0.675 (+/-0.029 for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 10}\n",
            "0.744 (+/-0.046 for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 100}\n",
            "0.761 (+/-0.029 for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 10, 'clf_gbc__n_estimators': 200}\n",
            "0.675 (+/-0.029 for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 10}\n",
            "0.744 (+/-0.046 for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 100}\n",
            "0.761 (+/-0.029 for {'clf_gbc__learning_rate': 0.1, 'clf_gbc__max_leaf_nodes': 20, 'clf_gbc__n_estimators': 200}\n",
            "\n",
            "Detailed classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.86      0.81      1288\n",
            "           1       0.79      0.67      0.72       996\n",
            "\n",
            "    accuracy                           0.78      2284\n",
            "   macro avg       0.78      0.77      0.77      2284\n",
            "weighted avg       0.78      0.78      0.78      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAXe0xG_KHoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6HjA6UDKO0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSZcuflCKQF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}